using Microsoft.Extensions.Logging;
using Moq;
using Newtonsoft.Json;
using spider.Converter;
using spider.Services;


namespace spiderTests;

[TestFixture]
public class Tests
{
    private Mock<IGitHubGraphqlService> _spiderGithubGraphqlService;
    private GraphqlDataConverter _graphqlDataConverter;
    // private Logger<GitHubGraphqlService> _logger;
    // private JsonSerializer _jsonSerializer;
    // private JsonReader _jsonReader;
    public string SearchReturn = @"{""search"":{""repositoryCount"":14930,""pageInfo"":{""startCursor"":""Y3Vyc29yOjE="",""endCursor"":""Y3Vyc29yOjU="",""hasNextPage"":true},""nodes"":[{""name"":""Agriculture_KnowledgeGraph"",""id"":""R_kgDOBqzb0A"",""defaultBranchRef"":{""name"":""master"",""target"":{""history"":{""edges"":[{""node"":{""committedDate"":""2021-07-15T05:56:22Z""}}]}}},""createdAt"":""2017-11-25T09:26:26Z"",""description"":""农业知识图谱(AgriKG)：农业领域的信息检索，命名实体识别，关系抽取，智能问答，辅助决策"",""stargazerCount"":3681,""languages"":{""totalSize"":535793,""edges"":[{""size"":480675,""node"":{""name"":""Python""}},{""size"":54781,""node"":{""name"":""Jupyter Notebook""}},{""size"":337,""node"":{""name"":""Shell""}}]},""owner"":{""login"":""qq547276542""},""repositoryTopics"":{""nodes"":[{""topic"":{""name"":""knowledge-graph""}},{""topic"":{""name"":""named-entity-recognition""}},{""topic"":{""name"":""relation-extraction""}},{""topic"":{""name"":""question-answering""}}]},""readmeCaps"":{""text"":""# Agricultural Knowledge Graph\n\n由于工作原因，该项目已停止维护。因此项目代码仅供参考，项目中包含的数据可免费用于学术等非商业用途。\n> 相关工作请引用paper: \n> - AgriKG: An Agricultural Knowledge Graph and Its Applications[C]. DASFAA (3) 2019: 533-537\n\n## 项目介绍：\n\n本项目是上海市《农业信息服务平台及农业大数据综合利用研究》子课题《上海农业农村大数据共享服务平台建设和应用》的研究成果。\n\n该课题是由上海市农业委员会信息中心主持，以“致富农民、服务市民、提高行政管理效能”为目标，充分发挥大数据在农业农村发展中的重要功能和巨大潜力，重点建设上海市级农业农村大数据中心，促进信息资源的共建共享和创新应用。\n\n华东师范大学数据科学与工程学院（以下简称华师大数据学院）作为课题主要参与单位以实现智慧农业为目标，探索农业大数据分析、挖掘和综合应用。华师大课题组在前期国家重点研发计划《大数据知识工程基础理论及其应用研究》研究基础上，在本项目中，基于碎片化农业大数据，构建面向智慧农业的知识图谱及其应用系统。\n\n\n\n\n>\n> ### 华东师范大学数据科学与工程学院\n>\n> #### 情境计算&知识图谱项目组\n> 学院官网：http://dase.ecnu.edu.cn   \n>\n> 项目组Github： https://github.com/ECNUdase\n>\n> 参与成员：\n>\n>| Title               | Name | Homepage                                 |\n>| ------------------- | ---- | ---------------------------------------- |\n>| Professor | Ming Gao  | [http://faculty.ecnu.edu.cn/s/2844/t/30305/main.jspy](http://faculty.ecnu.edu.cn/s/2844/t/30305/main.jspy)<br>[http://dase.ecnu.edu.cn/mgao](http://dase.ecnu.edu.cn/mgao) |\n>| Master              | Yuanzhe Chen  | [https://github.com/qq547276542](https://github.com/qq547276542) |\n>| Master              | Jung kuang  | [https://github.com/CrisJk](https://github.com/CrisJk) |\n\n\n\n## 目录结构：\n\n```\n.\n├── MyCrawler      // scrapy爬虫项目路径(已爬好)\n│   └── MyCrawler\n│       ├── data\n│       └── spiders\n├── data\\ processing    // 数据清洗(已无用)\n│   └── data\n├── demo     // django项目路径\n│   ├── Model  // 模型层，用于封装Item类，以及neo4j和csv的读取\n│   ├── demo   // 用于写页面的逻辑(View)\n│   ├── label_data    // 标注训练集页面的保存路径\n│   │   └── handwork\n│   ├── static    // 静态资源\n│   │   ├── css\n│   │   ├── js\n│   │   └── open-iconic\n│   ├── templates   // html页面\n│   └── toolkit   // 工具库，包括预加载，命名实体识别\n│   └── KNN_predict   \n├── KNN_predict    // KNN算法预测标签\n├── dfs_tree_crawler     // 爬取互动百科农业实体树形结构的爬虫\n└── wikidataSpider    //  爬取wiki中的关系\n```\n\n\n\n## 可复用资源\n\n- hudong_pedia.csv : 已经爬好的农业实体的百科页面的结构化csv文件\n- labels.txt： 5000多个手工标注的实体类别\n- predict_labels.txt:  KNN算法预测的15W多个实体的类别\n- /wikidataSpider/wikidataProcessing/wikidata_relation.csv: predict_labels.txt中实体在wikidata中对应的三元组关系\n- attributes.csv: 部分实体的属性(互动百科页面中直接得到)\n- wikidataSpider/weatherData/static_weather_list.csv： 气候类型列表\n- wikidataSpider/weatherData/weather_plant.csv：气候与植物的种植关系\n- wikidataSpider/weatherData/city_weather.csv：城市与气候的关系\n\n\n\n## 项目配置\n\n**0.安装基本环境：**\n\n确保安装好python3和Neo4j（任意版本）\n \n安装一系列pip依赖： cd至项目根目录，运行 sudo pip3 install -r requirement.txt\n\n**1.导入数据：**\n\n将hudong_pedia.csv导入neo4j：开启neo4j，进入neo4j控制台。将hudong_pedia.csv放入neo4j安装目录下的/import目录。在控制台依次输入：\n\n```\n// 将hudong_pedia.csv 导入\nLOAD CSV WITH HEADERS  FROM \""file:///hudong_pedia.csv\"" AS line  \nCREATE (p:HudongItem{title:line.title,image:line.image,detail:line.detail,url:line.url,openTypeList:line.openTypeList,baseInfoKeyList:line.baseInfoKeyList,baseInfoValueList:line.baseInfoValueList})  \n\n// 新增了hudong_pedia2.csv\nLOAD CSV WITH HEADERS  FROM \""file:///hudong_pedia2.csv\"" AS line  \nCREATE (p:HudongItem{title:line.title,image:line.image,detail:line.detail,url:line.url,openTypeList:line.openTypeList,baseInfoKeyList:line.baseInfoKeyList,baseInfoValueList:line.baseInfoValueList})  \n```\n```\n// 创建索引\nCREATE CONSTRAINT ON (c:HudongItem)\nASSERT c.title IS UNIQUE\n```\n\n以上两步的意思是，将hudong_pedia.csv导入neo4j作为结点，然后对titile属性添加UNIQUE（唯一约束/索引）\n\n*（如果导入的时候出现neo4j jvm内存溢出，可以在导入前，先把neo4j下的conf/neo4j.conf中的dbms.memory.heap.initial_size 和dbms.memory.heap.max_size调大点。导入完成后再把值改回去）*\n\n\n\n进入/wikidataSpider/wikidataProcessing中，将new_node.csv,wikidata_relation.csv,wikidata_relation2.csv三个文件放入neo4j的import文件夹中（运行relationDataProcessing.py可以得到这3个文件），然后分别运行\n```\n// 导入新的节点\nLOAD CSV WITH HEADERS FROM \""file:///new_node.csv\"" AS line\nCREATE (:NewNode { title: line.title })\n\n//添加索引\nCREATE CONSTRAINT ON (c:NewNode)\nASSERT c.title IS UNIQUE\n\n//导入hudongItem和新加入节点之间的关系\nLOAD CSV  WITH HEADERS FROM \""file:///wikidata_relation2.csv\"" AS line\nMATCH (entity1:HudongItem{title:line.HudongItem}) , (entity2:NewNode{title:line.NewNode})\nCREATE (entity1)-[:RELATION { type: line.relation }]->(entity2)\n\nLOAD CSV  WITH HEADERS FROM \""file:///wikidata_relation.csv\"" AS line\nMATCH (entity1:HudongItem{title:line.HudongItem1}) , (entity2:HudongItem{title:line.HudongItem2})\nCREATE (entity1)-[:RELATION { type: line.relation }]->(entity2)\n```\n\n**导入实体属性(数据来源: 互动百科)**\n\n将attributes.csv放到neo4j的import目录下，然后执行\n\n```cypher\nLOAD CSV WITH HEADERS FROM \""file:///attributes.csv\"" AS line\nMATCH (entity1:HudongItem{title:line.Entity}), (entity2:HudongItem{title:line.Attribute})\nCREATE (entity1)-[:RELATION { type: line.AttributeName }]->(entity2);\n                                                            \nLOAD CSV WITH HEADERS FROM \""file:///attributes.csv\"" AS line\nMATCH (entity1:HudongItem{title:line.Entity}), (entity2:NewNode{title:line.Attribute})\nCREATE (entity1)-[:RELATION { type: line.AttributeName }]->(entity2);\n                                                            \nLOAD CSV WITH HEADERS FROM \""file:///attributes.csv\"" AS line\nMATCH (entity1:NewNode{title:line.Entity}), (entity2:NewNode{title:line.Attribute})\nCREATE (entity1)-[:RELATION { type: line.AttributeName }]->(entity2);\n                                                            \nLOAD CSV WITH HEADERS FROM \""file:///attributes.csv\"" AS line\nMATCH (entity1:NewNode{title:line.Entity}), (entity2:HudongItem{title:line.Attribute})\nCREATE (entity1)-[:RELATION { type: line.AttributeName }]->(entity2)  \n\n//我们建索引的时候带了label，因此只有使用label时才会使用索引，这里我们的实体有两个label，所以一共做2*2=4次。当然，可以建立全局索引，即对于不同的label使用同一个索引\n                                                            \n          \n                                                                                                                         \n```\n\n**导入气候名称:**\n\n将wikidataSpider/weatherData/static_weather_list.csv放在指定的位置(import文件夹下)\n\n```\n//导入节点\nLOAD CSV WITH HEADERS FROM \""file:///static_weather_list.csv\"" AS line\nMERGE (:Weather { title: line.title })\n\n//添加索引\nCREATE CONSTRAINT ON (c:Weather)\nASSERT c.title IS UNIQUE\n```\n\n**导入气候与植物的关系**\n\n```\n\n将wikidataSpider/weatherData/weather_plant.csv放在指定的位置(import文件夹下)\n//导入hudongItem和新加入节点之间的关系\nLOAD CSV  WITH HEADERS FROM \""file:///weather_plant.csv\"" AS line\nMATCH (entity1:Weather{title:line.Weather}) , (entity2:HudongItem{title:line.Plant})\nCREATE (entity1)-[:Weather2Plant { type: line.relation }]->(entity2)\n导入城市的气候\n\n将city_weather.csv放在指定的位置(import 文件夹下)\n(这步大约需要15分钟左右)\n//导入城市对应的气候\nLOAD CSV WITH HEADERS FROM \""file:///city_weather.csv\"" AS line\nMATCH (city{title:line.city}) , (weather{title:line.weather})\nCREATE (city)-[:CityWeather { type: line.relation }]->(weather)\n```\n\n\n以上步骤是导入爬取到的关系\n\n\n**2.下载词向量模型：（如果只是为了运行项目，步骤2可以不做，预测结果已经离线处理好了）**\n \n~~http://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.zh.zip  \n  将wiki.zh.bin放入 KNN_predict 目录 。~~\n\n\n**3.修改Neo4j用户**\n\n进入demo/Model/neo_models.py,修改第9行的neo4j账号密码，改成你自己的\n\n**4.启动服务**\n\n进入demo目录，然后运行脚本：\n\n```\nsudo sh django_server_start.sh\n```\n\n这样就成功的启动了django。我们进入8000端口主页面，输入文本，即可看到以下命名实体和分词的结果（确保django和neo4j都处于开启状态）\n\n----------------------\n###  (update 2018.11.11)\n添加了农业知识问答\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/1541921074856.jpg)\n\n###  (update 2018.10.26) \n- 修改部分配置信息\n- 关系查询中，添加了2个实体间的最短路查询，从而挖掘出实体之间一些奇怪的隐含关系\n\n![image](https://i.loli.net/2018/10/27/5bd3bf6ce4472.jpg)\n\n### 农业实体识别+实体分类\n\n\n![image](https://raw.githubusercontent.com/qq547276542/blog_image/master/agri/2.png)\n\n点击实体的超链接，可以跳转到词条页面（词云采用了词向量技术）：\n\n![image](https://raw.githubusercontent.com/qq547276542/blog_image/master/agri/3.png)\n\n### 实体查询\n\n实体查询部分，我们能够搜索出与某一实体相关的实体，以及它们之间的关系：\n![image](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/entitySearch.png)\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/entitySearch2.png)\n\n### 关系查询\n\n关系查询即查询三元组关系entity1-[relation]->entity2 , 分为如下几种情况:\n\n* 指定第一个实体entity1\n* 指定第二个实体entity2\n* 指定第一个实体entity1和关系relation\n* 指定关系relation和第二个实体entity2\n* 指定第一个实体entity1和第二个实体entity2\n* 指定第一个实体entity1和第二个实体entity2以及关系relation\n\n下图所示，是指定关系relation和第二个实体entity2的查询结果\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/relationSearch.png)\n\n\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/relationSearch2.png)\n\n### 知识的树形结构\n\n农业知识概览部分，我们能够列出某一农业分类下的词条列表，这些概念以树形结构组织在一起：\n\n![image](https://raw.githubusercontent.com/qq547276542/blog_image/master/agri/6.png)\n\n农业分类的树形图：\n\n![image](https://raw.githubusercontent.com/qq547276542/blog_image/master/agri/5.png)\n\n### 训练集标注\n\n我们还制作了训练集的手动标注页面，每次会随机的跳出一个未标注过的词条。链接：http://localhost:8000/tagging-get , 手动标注的结果会追加到/label_data/labels.txt文件末尾：\n\n我们将这部分做成了小工具，可复用：https://github.com/qq547276542/LabelMarker\n\n![image](https://raw.githubusercontent.com/qq547276542/blog_image/master/agri/4.png)\n\n(update 2018.04.07)  同样的，我们制作了标注关系提取训练集的工具，如下图所示\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/tagging.JPG)\n\n如果Statement的标签是对的，点击True按钮；否则选择一个关系，或者输入其它关系。若当前句子无法判断，则点击Change One按钮换一条数据。\n\n说明:　Statement是/wikidataSpider/TrainDataBaseOnWiki/finalData中train_data.txt中的数据，我们将它转化成json,导入到mongoDB中。标注好的数据同样存在MongoDB中另一个Collection中。关于Mongo的使用方法可以参考官方tutorial，或者利用这篇文章简单了解一下[MongoDB](http://crisjk.site/2018/04/04/MongoDB-Tutorial/) \n\n我们在MongoDB中使用两个Collections，一个是train_data，即未经人工标注的数据；另一个是test_data，即人工标注好的数据。\n\n![](https://raw.githubusercontent.com/CrisJk/crisjk.github.io/master/resource/pictures/Agriculture-KnowledgeGraph-Data-README/mongo.png)\n\n\n\n**使用方法**: 启动neo4j,mongodb之后，进入demo目录，启动django服务，进入127.0.0.1:8000/tagging即可使用\n\n\n\n\n## 思路\n\n### 命名实体识别:\n\n使用thulac工具进行分词，词性标注，命名实体识别（仅人名，地名，机构名） \n为了识别农业领域特定实体，我们需要： \n\n1. 分词，词性标注，命名实体识别 \n2. 以识别为命名实体（person，location，organzation）的，若实体库没有，可以标注出来 \n3. 对于非命名实体部分，采用一定的词组合和词性规则，在O(n)时间扫描所有分词，过滤掉不可能为农业实体的部分（例如动词肯定不是农业实体） \n4. 对于剩余词及词组合，匹配知识库中以分好类的实体。如果没有匹配到实体，或者匹配到的实体属于0类（即非实体），则将其过滤掉。 \n5. 实体的分类算法见下文。\n\n\n### 实体分类：\n\n#### 特征提取：\n\n![image](https://raw.githubusercontent.com/qq547276542/blog_image/master/agri/1.png)\n\n\n#### 分类器：KNN算法\n\n- 无需表示成向量，比较相似度即可\n- K值通过网格搜索得到\n\n#### 定义两个页面的相似度sim(p1,p2)：\n\n- \n  title之间的词向量的余弦相似度(利用fasttext计算的词向量能够避免out of vocabulary)\n- 2组openType之间的词向量的余弦相似度的平均值\n- 相同的baseInfoKey的IDF值之和（因为‘中文名’这种属性贡献应该比较小）\n- 相同baseInfoKey下baseInfoValue相同的个数\n- 预测一个页面时，由于KNN要将该页面和训练集中所有页面进行比较，因此每次预测的复杂度是O(n)，n为训练集规模。在这个过程中，我们可以统计各个分相似度的IDF值，均值，方差，标准差，然后对4个相似度进行标准化:**(x-均值)/方差**\n- 上面四个部分的相似度的加权和为最终的两个页面的相似度，权值由向量weight控制，通过10折叠交叉验证+网格搜索得到\n\n\n### Labels：（命名实体的分类）\n\n| Label | NE Tags                                  | Example                                  |\n| ----- | ---------------------------------------- | ---------------------------------------- |\n| 0     | Invalid（不合法）                             | “色调”，“文化”，“景观”，“条件”，“A”，“234年”（不是具体的实体，或一些脏数据） |\n| 1     | Person（人物，职位）                            | “袁隆平”，“副市长”                         |\n| 2     | Location（地点，区域）                          | “福建省”，“三明市”，“大明湖”                        |\n| 3     | Organization（机构，会议）                      | “华东师范大学”，“上海市农业委员会”                      |\n| 4     | Political economy（政治经济名词）                | “惠农补贴”，“基本建设投资”                          |\n| 5     | Animal（动物学名词，包括畜牧类，爬行类，鸟类，鱼类，等）          | “绵羊”，“淡水鱼”，“麻雀”                          |\n| 6     | Plant（植物学名词，包括水果，蔬菜，谷物，草药，菌类，植物器官，其他植物）  | “苹果”，“小麦”，“生菜”                           |\n| 7     | Chemicals（化学名词，包括肥料，农药，杀菌剂，其它化学品，术语等）    | “氮”，“氮肥”，“硝酸盐”，“吸湿剂”                     |\n| 8     | Climate（气候，季节）                           | “夏天”，“干旱”                                |\n| 9     | Food items（动植物产品）                        | “奶酪”，“牛奶”，“羊毛”，“面粉”                      |\n| 10    | Diseases（动植物疾病）                          | “褐腐病”，“晚疫病”                              |\n| 11    | Natural Disaster（自然灾害）                   | “地震”，“洪水”，“饥荒”                           |\n| 12    | Nutrients（营养素，包括脂肪，矿物质，维生素，碳水化合物等）       | “维生素A”，\""钙\""                               |\n| 13    | Biochemistry（生物学名词，包括基因相关，人体部位，组织器官，细胞，细菌，术语） | “染色体”，“血红蛋白”，“肾脏”，“大肠杆菌”                 |\n| 14    | Agricultural implements（农机具，一般指机械或物理设施）  | “收割机”，“渔网”                               |\n| 15    | Technology(农业相关术语，技术和措施)                 | “延后栽培\""，“卫生防疫”，“扦插”                       |\n| 16    | other（除上面类别之外的其它名词实体，可以与农业无关但必须是实体）      | “加速度\""，“cpu”，“计算机”，“爱鸟周”，“人民币”，“《本草纲目》”，“花岗岩” |\n\n\n### 关系抽取\n\n使用远程监督方法构建数据集，利用tensorflow训练PCNN模型\n详情见： [relationExtraction](https://github.com/qq547276542/Agriculture_KnowledgeGraph/tree/master/relationExtraction)\n""},""readmeLower"":null,""readmeFstCaps"":null,""readmerstCaps"":null,""readmerstLower"":null,""readmerstFstCaps"":null},{""name"":""awesome-agriculture"",""id"":""R_kgDOB88ZBg"",""defaultBranchRef"":{""name"":""master"",""target"":{""history"":{""edges"":[{""node"":{""committedDate"":""2023-07-06T02:11:54Z""}}]}}},""createdAt"":""2018-04-25T13:44:25Z"",""description"":""Open source technology for agriculture, farming, and gardening"",""stargazerCount"":1107,""languages"":{""totalSize"":0,""edges"":[]},""owner"":{""login"":""brycejohnston""},""repositoryTopics"":{""nodes"":[{""topic"":{""name"":""agriculture""}},{""topic"":{""name"":""awesome-list""}},{""topic"":{""name"":""farming""}},{""topic"":{""name"":""farm""}},{""topic"":{""name"":""plants""}},{""topic"":{""name"":""agricultural""}},{""topic"":{""name"":""crop""}},{""topic"":{""name"":""soil""}},{""topic"":{""name"":""grower""}},{""topic"":{""name"":""weather""}},{""topic"":{""name"":""awesome""}},{""topic"":{""name"":""gardening""}}]},""readmeCaps"":{""text"":""# Awesome Agriculture [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n\n> A curated list of awesome open source technology for agriculture, farming, and gardening.\n\n[Agriculture](https://en.wikipedia.org/wiki/Agriculture) is the science and art of cultivating plants and livestock for food and materials.\n\nContributions welcome! Please follow the [contributing guidelines](https://github.com/beaorn/awesome-agriculture/blob/master/contributing.md).\n\n## Contents\n\n- [Automation and Robotics](#automation-and-robotics)\n- [Calculators](#calculators)\n- [Climate, Environment and Weather](#climate-environment-and-weather)\n- [Crop Modeling, Phenotyping, and Pathology](#crop-modeling-phenotyping-and-pathology)\n- [Datasets](#datasets)\n- [Data Standardization, Interoperability and APIs](#data-standardization-interoperability-and-apis)\n- [Farm Management Systems and Record Keeping](#farm-management-systems-and-record-keeping)\n- [Geospatial and GIS](#geospatial-and-gis)\n- [IoT, Hardware](#iot-hardware)\n- [Knowledgebases and Learning Resources](#knowledgebases-and-learning-resources)\n- [Machine Learning and AI](#machine-learning-and-ai)\n- [Remote Sensing and Imagery](#remote-sensing-and-imagery)\n\n## Automation and Robotics\n\n- [Ant Robotics](https://antrobotics.de/) development from Ecoterra bot\n- [Acorn Rover](https://github.com/Twisted-Fields) precision farming rover, Odrive, Python.\n- [Earth Rover](https://github.com/earthrover) Ag AGV ROS1 precision farming rover \n- [EcoTerra Bot](https://ecoterrabot.com/) Delta & Rover\n- [FarmBot](https://github.com/farmbot) -  Open source precision gardening project.\n- [Fields2Cover](https://github.com/Fields2Cover/Fields2Cover) - Robust and efficient coverage paths for autonomous agricultural vehicles.\n- [Romi project](https://media.romi-project.eu/documents/index.html) Europe-funded research project \n- [ROS Agriculture](http://rosagriculture.org/) - Open Source community focusing on using Robot Operating System to empower farmers with robotics tools. \n- [Weedinator](https://hackaday.io/project/53896-weedinator-2019) Line following weeding robot\n\n## Calculators\n\n- [farm-calculators](https://github.com/brycejohnston/farm-calculators) - WordPress plugin for calculating various farming and crop related information.\n\n## Climate, Environment and Weather\n\n- [agroclimatology](https://github.com/brycejohnston/agroclimatology) - Ruby client for interacting with the NASA (POWER) Agroclimatology Web Resource.\n- [evapotranspiration](https://github.com/brycejohnston/evapotranspiration) - Ruby library for calculating reference crop evapotranspiration (ETo).\n- [frostline](https://github.com/waldoj/frostline) - A dataset, API, and python parser for USDA plant hardiness zones.\n- [GSODR](https://github.com/ropensci/GSODR) - Global summary daily weather data in R.\n- [iem](https://github.com/akrherz/iem) - Code that makes the Iowa Environmental Mesonet run.\n- [PyETo](https://github.com/woodcrafty/PyETo) - Python package for calculating reference/potential evapotranspiration (ETo).\n- [pyTSEB](https://github.com/hectornieto/pyTSEB) - A python two source energy balance model for estimation of evapotranspiration with remote sensing data.\n- [soilDB](https://github.com/ncss-tech/soilDB) - R library for simplified access to NCSS soil databases.\n\n## Crop Modeling, Phenotyping, and Pathology\n\n- [Open Plant Pathology](https://www.openplantpathology.org/) - A community that values open data and computational tools for advancing epidemiology and pathogen population biology and ecology.\n\n## Datasets\n- [Growstuff](https://www.growstuff.org/crops) Record keeping & crop database, nice API\n- [CWFID](https://github.com/cwfid/dataset) - Dataset comprising field images, vegetation segmentation masks and crop/weed plant type annotations.\n- [TERRA REF](https://terraref.org) - 1PB public domain high resolution sensor data from sorghum breeding trials ([data publication](https://doi.org/10.5061/dryad.4b8gtht99) with large files available on [globus.org at ncsa#terra-public](https://app.globus.org/file-manager?origin_id=e8feaff4-96cd-11ea-bf90-0e6cccbb0103&origin_path=%2F))\n\n## Data Standardization, Interoperability and APIs\n\n- [AgGateway’s ADAPT Toolkit](https://adaptframework.org) - Open Source project providing tools to simplify communication between growers, their machines, and their partners.\n- [Agstack](https://github.com/agstack) - Open-Source Digital Infrastructure for the Agriculture Ecosystem.\n- [agx-ruby](https://github.com/brycejohnston/agx-ruby) - Ruby client for Proagrica's agX platform APIs.\n- [API-Code-Samples](https://github.com/aWhereAPI/API-Code-Samples) - Contains aWhere's API platform code samples.\n- [ClearAg-API-Examples](https://github.com/IterisClearAg/ClearAg-API-Examples) - A collection of code examples using the ClearAg APIs.\n- [JDLinkMachineDataAPI-OAuth2-CSharp-Example](https://github.com/JohnDeere/JDLinkMachineDataAPI-OAuth2-CSharp-Example) - CSharp JDLink Machine Data API client example.\n- [Open Ag Data Alliance](https://github.com/oada) - OADA is an open project designed to bring interoperability, security, and privacy to agricultural data.\n- [MyJohnDeereAPI-OAuth2-Java-Example](https://github.com/JohnDeere/MyJohnDeereAPI-OAuth2-Java-Example) - Java MyJohnDeere API client example.\n- [MyJohnDeereAPI-OAuth2-NodeJS-Example](https://github.com/JohnDeere/MyJohnDeereAPI-OAuth2-NodeJS-Example) - Node.js MyJohnDeere API client example.\n- [MyJohnDeereAPI-OAuth2-Python-Example](https://github.com/JohnDeere/MyJohnDeereAPI-OAuth2-Python-Example) - Python MyJohnDeere API client example.\n- [OpenTeam](https://openteam.community/) - Open Technology Ecosystem for Agricultural Management\n- [SampleData](https://github.com/JohnDeere/SampleData) - Sample datacards, shapefiles, and other files you can use for testing.\n- [SencropAPI-JavaScript-Client](https://github.com/sencrop/sencrop-js-api-client) - Sencrop API Javascript client implementation. Read and manage Sencrop weather stations.\n\n## Farm Management Systems and Record Keeping\n\n- [AgroSense](https://bitbucket.org/corizon/agrosense) - Free and open source farm management suite built with Java.\n- [farmOS](https://github.com/farmOS/farmOS) - Web-based farm record keeping application built with Drupal and PHP.\n- [Ekylibre](https://github.com/ekylibre/ekylibre) - Farm management information system for farmers and small enterprises built with Ruby on Rails and PostgreSQL/PostGIS.\n- [Soil Mate](https://github.com/Open-Source-Agriculture/soil_mate) - Helper app designed to assist the collection of soil data.\n- [Tania](https://github.com/Tanibox/tania-core) - Free and open source farming management system for everyone built with Go and Vue.js.\n\n## Geospatial and GIS\n\n### GIS Resources\n\n- [Awesome GIS](https://github.com/sshuair/awesome-gis) - Awesome GIS is a list collecting abundant GIS related sources.\n\n### GIS Platforms\n\n- [QGIS](https://qgis.org) - QGIS is a free, open source, cross platform (lin/win/mac) geographical information system.\n\n### Shapefiles\n\n- [pyshp](https://github.com/GeospatialPython/pyshp) - Reads and writes ESRI Shapefiles in pure Python.\n- [rgeo-shapefile](https://github.com/rgeo/rgeo-shapefile) - RGeo Shapefile is an optional module for RGeo for reading geospatial data from ESRI shapefiles in Ruby.\n\n## IoT, Hardware\n\n- [AgOpenGPS](https://github.com/farmerbriantee/AgOpenGPS) - Ag precision mapping and section control software.\n- [DRO-Matic](https://github.com/drolsen/DRO-Matic) - Fully Automated Hydroponic OS for DIY DRO-Matic cabinets - Nutrient dosing, irrigation, topoffs, timers, EC & pH drift fixing.\n- [Farm-Data-Relay-System](https://github.com/timmbogner/Farm-Data-Relay-System) - System using ESP-NOW, LoRa, and other protocols to transport sensor data in remote areas without relying on WiFi.\n- [Farm Hack](https://farmhack.org/tools) - Worldwide community of farmers that build and modify our own tools.\n- [Open Agriculture Foundation](https://github.com/OpenAgricultureFoundation) -  Open Source ecosystem of technologies that enable and promote transparency, networked experimentation, education, and hyper-local production.\n- [OpenMinder](https://github.com/autogrow/openminder) - Open Source Rootzone Monitoring, API and open source hat for the RaspberryPi.\n- [OpenWeedLocator](https://github.com/geezacoleman/OpenWeedLocator) - Open Source, low-cost, image-based weed detection device for in-crop and fallow scenarios.\n\n## Knowledgebases and Learning Resources\n\n- [Harvest Helper](https://github.com/damwhit/harvest_helper) -  Provides growing, harvesting and recipe information for the 45 plants in the database as well as a JSON API.\n- [OpenFarm](https://github.com/openfarmcc/OpenFarm) - A free and open database for farming and gardening knowledge built with Ruby on Rails.\n\n## Machine Learning and AI\n- [AgML](https://github.com/Project-AgML/AgML) - Centralized framework for agricultural machine learning.\n- [agridat](https://github.com/kwstat/agridat) - R package providing an extensive collection of datasets from agricultural experiments.\n- [Crop Yield Prediction](https://github.com/JiaxuanYou/crop_yield_prediction) - Deep gaussian process for crop yield prediction based on remote sensing data.\n- [Deep Learning for Biologists with Keras](https://github.com/totti0223/deep_learning_for_biologists_with_keras) - Tutorials for deep learning based analysis (mainly) on biological relavent themes.\n- [FarmVibes.AI](https://github.com/microsoft/farmvibes-ai) - Multi-Modal GeoSpatial ML Models for Agriculture and Sustainability.\n- [PlantCV](https://github.com/danforthcenter/plantcv) - Plant phenotyping software using computer vision.\n\n## Remote Sensing and Imagery\n\n- [Awesome Sentinel](https://github.com/Fernerkundung/awesome-sentinel) - A curated list of awesome tools, tutorials and APIs related to data from the Copernicus Sentinel Satellites.\n- [Raster Vision](https://github.com/azavea/raster-vision) - Deep learning for aerial/satellite imagery.\n- [Sen2Agri](https://github.com/Sen2Agri/Sen2Agri-System) - Software system processing high resolution satellite images for agricultural purposes.\n- [Awesome Vegetation Index](https://github.com/px39n/Awesome-Vegetation-Index) - List of reference, applications of common Vegetation Indices for Multi-spectral, hyper-spectral and UAV images.\n\n## License\n\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n\nTo the extent possible under law, [Bryce Johnston](https://github.com/brycejohnston) has waived all copyright and related or neighboring rights to this work.\n""},""readmeLower"":null,""readmeFstCaps"":null,""readmerstCaps"":null,""readmerstLower"":null,""readmerstFstCaps"":null},{""name"":""Agriculture"",""id"":""R_kgDOCLdA4A"",""defaultBranchRef"":{""name"":""master"",""target"":{""history"":{""edges"":[{""node"":{""committedDate"":""2018-08-27T00:44:12Z""}}]}}},""createdAt"":""2018-08-27T00:29:53Z"",""description"":""长春智信创联科技有限公司，智慧农业项目源码。 智慧农业物联网应用平台将物联网技术运用到传统农业中去，运用传感器和软件通过移动平台或者电脑平台对农业生产进行控制，依托部署在农业生产现场的各种传感节点（环境温湿度、土壤成分、PH值、二氧化碳、光照强度、气压、图像等）和无线通信网络实现农业生产环境的智能感知、智能预警、智能决策、智能分析、专家在线指导，为农业生产提供精准化种植养殖、可视化管理、智能化决策。"",""stargazerCount"":64,""languages"":{""totalSize"":2888405,""edges"":[{""size"":74311,""node"":{""name"":""Java""}},{""size"":11857,""node"":{""name"":""CSS""}},{""size"":2791683,""node"":{""name"":""JavaScript""}},{""size"":10554,""node"":{""name"":""HTML""}}]},""owner"":{""login"":""ldzandsmile""},""repositoryTopics"":{""nodes"":[]},""readmeCaps"":null,""readmeLower"":null,""readmeFstCaps"":null,""readmerstCaps"":null,""readmerstLower"":null,""readmerstFstCaps"":null},{""name"":""Agriculture-KnowledgeGraph-Data"",""id"":""R_kgDOBuVFbw"",""defaultBranchRef"":{""name"":""master"",""target"":{""history"":{""edges"":[{""node"":{""committedDate"":""2021-08-11T09:02:10Z""}}]}}},""createdAt"":""2017-12-29T05:10:05Z"",""description"":""对知识库Wikidata的爬虫以及数据处理脚本 将三元组关系对齐到语料库的脚本 获取知识图谱数据的脚本"",""stargazerCount"":253,""languages"":{""totalSize"":2064385,""edges"":[{""size"":6061,""node"":{""name"":""Jupyter Notebook""}},{""size"":543856,""node"":{""name"":""Python""}},{""size"":337,""node"":{""name"":""Shell""}},{""size"":283112,""node"":{""name"":""HTML""}},{""size"":234008,""node"":{""name"":""CSS""}},{""size"":946866,""node"":{""name"":""JavaScript""}},{""size"":33472,""node"":{""name"":""PHP""}},{""size"":163,""node"":{""name"":""Makefile""}},{""size"":4866,""node"":{""name"":""CoffeeScript""}},{""size"":6713,""node"":{""name"":""Go""}},{""size"":4931,""node"":{""name"":""Less""}}]},""owner"":{""login"":""CrisJk""},""repositoryTopics"":{""nodes"":[{""topic"":{""name"":""knowledge-graph""}},{""topic"":{""name"":""wikidata""}},{""topic"":{""name"":""agriculture-knowledgegraph""}},{""topic"":{""name"":""wikiextractor""}}]},""readmeCaps"":null,""readmeLower"":{""text"":""\n# 2020.07.29\n# 由于工作原因，本项目不再维护，烦请谅解\n# 说明\n\n> 本项目为一些用于获取知识图谱中三元组关系的python脚本。包括爬取Wikidata数据的爬虫、爬取复旦知识工场数据的爬虫(由于知识工场限制爬取，这部分暂时不好用)、提取所有中文维基页面的脚本以及将Wikidata三元组数据对齐到中文维基页面语句的脚本。\n\n### 运行环境\n\npython3、 Scrapy、neo4j(仅对齐时需要)、MongoDB(标注关系数据集时需要)\n\n\n\n> 注意：下面所有爬虫执行命令scrapy crawl XXX 请在各个模块的根目录执行，否则可能由于路径问题找不到文件导致程序报错\n\n \n\n### Model&taggingDemo&toolkit训练集标注工具(update 2018.04.07)\n\n\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/tagging.JPG)\n\n用于标注训练集的工具，如果Statement的标签是对的，点击True按钮；否则选择一个关系，或者输入其它关系。若当前句子无法判断，则点击Change One按钮换一条数据。\n\n说明:　Statement是/TrainDataBaseOnWiki/finalData中train_data.txt中的数据，我们将它转化成json,导入到mongoDB中。标注好的数据同样存在MongoDB中另一个Collection中。关于Mongo的使用方法可以参考官方tutorial，或者利用这篇文章简单了解一下[MongoDB](http://crisjk.site/2018/04/04/MongoDB-Tutorial/) 。\n\n我们在MongoDB中使用两个Collections，一个是train_data，即未经人工标注的数据；另一个是test_data，即人工标注好的数据。\n\n![](https://raw.githubusercontent.com/CrisJk/crisjk.github.io/master/resource/pictures/Agriculture-KnowledgeGraph-Data-README/mongo.png)\n\n##### 使用方法\n\n启动neo4j,mongodb之后，进入taggingdemo目录，启动django服务，进入127.0.0.1:8000/tagging即可使用\n\n### wikidataCrawler\n\n**用来爬取wikidata上定义的所有关系**\n\nwikidata中的所有关系都汇总在该网页上[(链接)](https://www.wikidata.org/wiki/Wikidata:List_of_properties/Summary_table) ，wikidataCrawler将该网页下的汇总的所有关系及其对应的中文名称爬取下来，存储为json格式\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/wikiRelationSumary.png)\n\n##### 使用方法\n\n进入到wikidataCrawler目录下，运行`scrapy crawl relation`即可爬取wikidata中定义的所有关系。可以得到`relation.json`和`chrmention.json`。\n\n* `relation.json`内容: 关系的id，关系所属的大类，关系所属子类，对应的链接，关系的英文表示\n* `chrmention.json`内容: 关系的id，关系的中文表示（对于不包含中文表示的数据暂时不做处理）。\n\n\n\n将`relation.json`和`chrmention.json`的数据进行合并，运行`mergeChrmentionToRelation.ipynb`即可，得到的结果存储在`result.json`中，匹配失败的存在`fail.json` 中\n\n### wikientities\n\n**用来爬取实体，返回json格式**\n\n进入到wikientities目录下，运行`scrapy crawl entity`。可以得到 `entity.json`。\n\n`entity.json` 是以predict_labels.txt中的实体为搜索词，在wikidata上搜索返回的json内容。\n\n`entity.json`中还包括搜索词(即实体)以及实体所属的类别(和predict_labels.txt中一样)也加入json中存储。\n\n> 由于我目前想做一个农业领域的知识图谱，因此predict_label.txt中很多词都是关于农业的，若想爬取其他实体，则自己修改predict_label.txt中的数据即可。\n\n### wikidataRelation说明\n\n##### 用来爬取实体和实体间的关系三元组，返回三元组\n\nWikidata是一个开放的全领域的知识库，其中包含大量的实体以及实体间的关系。下图是一个wikidata的实体页面\n\n![](https://raw.githubusercontent.com/CrisJk/SomePicture/master/blog_picture/wikidataPage.png)\n\n\n\n从图中可以看到wikidata实体页面包含实体的描述和与该实体相关联的其它实体及对应的关系。\n\nwikidataRelation爬取得到的是实体和实体间的三元关系，例如`合成橡胶`和`石油`之间存在`material used`的关系，因此可以得到如下json格式的三元组：\n\n` {\""entity1\"": \""合成橡胶\"", \""relation\"": \""material used\"", \""entity2\"": \""石油\""}`\n\n##### 使用方法\n\n首先运行preProcess.py，得到readytoCrawl.json。然后进入到wikidataRelation目录下，运行scrapy crawl entityRelation。可以得到`entityRelation.json` 。\n\n`entityRelation.json`是利用`entity.json`中的所有实体为基础，获取与这些实体相关的其他实体和关系。\n\n### wikidataProcessing \n\n##### 用来处理得到的三元组关系(entityRelation.json)\n\n将得到的entityRelation.json 处理成csv，并且存入neo4j数据库。该文件夹下的两个文件`hudong_pedia.csv　`和`hudong_pedia2.csv` 是爬取互动百科相关页面得到的，对应的就是wikientities目录下的`predict_label.txt`中的实体。运行`relationDataProcessing.py` 可以得到`new_node.csv` (即从wikidata实体页面中爬取得到的实体不包含在`predict_label.txt`中的部分)、`wikidata_relation.csv`(predict_label.txt中实体之间的关系)以及`wikidata_relation2.csv`(predict_label.txt中实体和新发现实体间的关系)，将该目录下所有csv导入到neo4j中，具体操作参见[Agriculture_KnowledgeGraph](https://github.com/qq547276542/Agriculture_KnowledgeGraph) 中的项目部署部分。\n\n### CN_DBpediaCrawler\n\nCN_DBpedia限制访问，需要向复旦大学知识工场申请API，否则只能限制每分钟爬取次数，这里的爬虫还有些问题，暂时不能使用。\n\n### wikiextractor\n\nwikiextractor是用来获取维基百科语料的工具，维基百科有wiki dump可以直接下载：[下载链接]([http://download.wikipedia.com/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2](http://download.wikipedia.com/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2)) ,下载好之后，利用wikiextractor工具进行处理，可以剔除掉一些无用的信息，直接得到维基百科语料库。[wikiextractor工具链接](https://github.com/attardi/wikiextractor) ,下载并安装后，将wiki dump放在wikiextractor目录下，执行命令\n\n```shell\nbzcat zhwiki-latest-pages-articles.xml.bz2 | python WikiExtractor.py -b 500K -o extracted -\n```\n\n可以得到处理好的维基百科语料，在目录extractor下。\n\n\n\n由于得到的语料既有简体也有繁体，所以要进行繁简体转换。将本项目wikiextractor\\extracted目录下的三个python文件复制到你处理好的维基百科语料的目录(extractor)下，运行convLan.py便可以将繁体转化为简体。\n\n\n\n### TrainDataBaseOnWiki\n\n##### 用于将从wikidata知识库中获取的三元组关系对齐到中文维基的语料库上\n\n首先必须将`wikidataProcessing`目录下的csv导入到neo4j中，才能成功运行。运行`extractTrainingData.py`后，可以得到`train_data.txt` ，其内容包含:\n\nentity1pos\tentity1\tentity2pos\tentity2\tsetence\trelation\n\n(注:该文件夹下的parallelTrainingData.py是后来加的，用来得到NA关系的数据，可以参考这个代码来并行得到train_data.txt)\n\n从维基预料中对齐得到的训练集里面有很多属性关系(中文)，甚至还有些关系为空值，把这部分过滤掉，得到**filter_train_data_all.txt**\n\n```shell\npython filterRelation.py\n```\n\n有些python文件因为文件名变动可能会报错，修改文件名即可\n\n~~得到train_data.txt后，使用dataScrubbing.py处理得到的数据(参考，由于文件名变动一些代码可能运行不了),包括:~~\n\n* ~~错误处理(not necessary)~~\n\n  ~~**如果数据中有错误，利用该模块处理错误**~~\n\n  ~~部分句子有换行，把换行去掉~~\n\n  ~~第一次产生的数据train_data.txt，由于之前程序在切割字符串时出了问题，因此relation这一列不对，这里重新处理一下~~\n\n* ~~选择农业相关的数据~~\n\n  ~~从指定的train_data.txt中挑选出与农业有关的数据,~~\n\n~~运行~~\n\n~~python dataScrubbing.py handleError~~\n\n~~执行错误管理模块~~\n\n~~运行~~\n\n~~python dataScrubbing.py selectAgriculturalData filename~~\n\n~~执行数据选择模块~~\n\n### wikidataAnalyse\n\nwikidataAnalyse: 得到staticResult.txt,统计各种关系的分布情况\n\nextractEntityAttribute: 获取实体属性得到attributes.csv\n\ngetCorpus(弃用): 获得互动百科语料hudongBaikeCorpus.txt\n\n\n### hudongpediaCrawler\n\n包含中国各个城市的各种气候，以及爬取所有气候的互动百科页面\n\n\n### Labels：（命名实体的分类）\n\n| Label | NE Tags                                  | Example                                  |\n| ----- | ---------------------------------------- | ---------------------------------------- |\n| 0     | Invalid（不合法）                             | “色调”，“文化”，“景观”，“条件”，“A”，“234年”（不是具体的实体，或一些脏数据） |\n| 1     | Person（人物，职位）                            | “袁隆平”，“习近平”，“皇帝”                         |\n| 2     | Location（地点，区域）                          | “福建省”，“三明市”，“大明湖”                        |\n| 3     | Organization（机构，会议）                      | “华东师范大学”，“上海市农业委员会”                      |\n| 4     | Political economy（政治经济名词）                | “惠农补贴”，“基本建设投资”                          |\n| 5     | Animal（动物学名词，包括畜牧类，爬行类，鸟类，鱼类，等）          | “绵羊”，“淡水鱼”，“麻雀”                          |\n| 6     | Plant（植物学名词，包括水果，蔬菜，谷物，草药，菌类，植物器官，其他植物）  | “苹果”，“小麦”，“生菜”                           |\n| 7     | Chemicals（化学名词，包括肥料，农药，杀菌剂，其它化学品，术语等）    | “氮”，“氮肥”，“硝酸盐”，“吸湿剂”                     |\n| 8     | Climate（气候，季节）                           | “夏天”，“干旱”                                |\n| 9     | Food items（动植物产品）                        | “奶酪”，“牛奶”，“羊毛”，“面粉”                      |\n| 10    | Diseases（动植物疾病）                          | “褐腐病”，“晚疫病”                              |\n| 11    | Natural Disaster（自然灾害）                   | “地震”，“洪水”，“饥荒”                           |\n| 12    | Nutrients（营养素，包括脂肪，矿物质，维生素，碳水化合物等）       | “维生素A”，\""钙\""                               |\n| 13    | Biochemistry（生物学名词，包括基因相关，人体部位，组织器官，细胞，细菌，术语） | “染色体”，“血红蛋白”，“肾脏”，“大肠杆菌”                 |\n| 14    | Agricultural implements（农机具，一般指机械或物理设施）  | “收割机”，“渔网”                               |\n| 15    | Technology(农业相关术语，技术和措施)                 | “延后栽培\""，“卫生防疫”，“扦插”                       |\n| 16    | other（除上面类别之外的其它名词实体，可以与农业无关但必须是实体）      | “加速度\""，“cpu”，“计算机”，“爱鸟周”，“人民币”，“《本草纲目》”，“花岗岩” |\n\n""},""readmeFstCaps"":null,""readmerstCaps"":null,""readmerstLower"":null,""readmerstFstCaps"":null},{""name"":""agriculture"",""id"":""R_kgDOGk75uQ"",""defaultBranchRef"":{""name"":""develop"",""target"":{""history"":{""edges"":[{""node"":{""committedDate"":""2023-09-24T04:34:19Z""}}]}}},""createdAt"":""2021-12-24T06:15:35Z"",""description"":""Agriculture Domain for ERPNext"",""stargazerCount"":30,""languages"":{""totalSize"":48705,""edges"":[{""size"":34587,""node"":{""name"":""Python""}},{""size"":14118,""node"":{""name"":""JavaScript""}}]},""owner"":{""login"":""frappe""},""repositoryTopics"":{""nodes"":[]},""readmeCaps"":{""text"":""## Agriculture\n\nThe Agriculture Domain of ERPNext comes with features to record crops and land, track plant, soil, water, weather analytics, and even track diseases and fertilizers. You can check out the following topics after this brief introduction to the agriculture module in ERPNext.\n\n\n### Installation\n\nUsing bench, [install ERPNext](https://github.com/frappe/bench#installation) as mentioned here.\n\nOnce ERPNext is installed, add agriculture app to your bench by running\n```sh\n$ bench get-app agriculture\n```\n\nAfter that, you can install agriculture app on required site by running\n\n```sh\n$ bench --site demo.com install-app agriculture\n```\n\n\n### License\n\nGNU GPL V3. See [license.txt](https://github.com/frappe/agriculture/blob/develop/license.txt) for more information.\n""},""readmeLower"":null,""readmeFstCaps"":null,""readmerstCaps"":null,""readmerstLower"":null,""readmerstFstCaps"":null}]},""rateLimit"":{""remaining"":4985,""cost"":1,""limit"":5000,""resetAt"":""2023-12-06T12:53:54Z"",""used"":15}}";
        
    [SetUp]
    public void Setup()
    {
        // _jsonSerializer = new JsonSerializer();
        // _logger = new Logger<GitHubGraphqlService>(new LoggerFactory());
         _spiderGithubGraphqlService = new Moq.Mock<IGitHubGraphqlService>();
         _spiderGithubGraphqlService.Setup(x => x.QueryRepositoriesByName(It.IsAny<string>()
                 , It.IsAny<int>(), It.IsAny<string?>(), It.IsAny<int>()))
             .ReturnsAsync(JsonConvert.DeserializeObject<SpiderData>(SearchReturn));
         _graphqlDataConverter = new GraphqlDataConverter();
    }

    [Test]
    public async Task SuccessfullyConvertSearchResultToProjects()
    {
        var result = await _spiderGithubGraphqlService.Object.QueryRepositoriesByName("Agriculture", 10, null, 1);
        Assert.That(result.Search, Is.Not.EqualTo(null));
        var converted = _graphqlDataConverter.SearchToProjects(result);
        Assert.That(converted.Count(), Is.EqualTo(5));
        Assert.That();
    }
    
    // [Test]
    // public async Task TopicSearchResultTest()
    // {
    //     var result = await _spiderGithubGraphqlService.QueryRepositoriesByTopic("Agriculture", 10, null);
    //     Assert.That(result.Topic, Is.Not.EqualTo(null));
    // }
    //
    // [Test]
    // public async Task RepoToProjectTest()
    // {
    //     var result = await _spiderGithubGraphqlService.QueryRepositoriesByName("Agriculture", 10, null);
    //     var projects = _graphqlDataConverter.SearchToProjects(result);
    //     Assert.That(projects, Is.Not.EqualTo(null));
    // }
}