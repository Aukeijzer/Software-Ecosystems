"""
Module: preprocessing

This module provides functions for preprocessing text data, including the
 removal of Markdown layout, tokenization, removal of punctuation and
 non-alphabetic characters and lemmatization.

Functions:
- preprocess_docs: Preprocess a list of documents using the preprocess_document
 function.
- preprocess_document: Preprocess a single document by removing Markdown
 layout, tokenizing text, removing punctuation and non-alphabetic characters
 and lemmatizing words.
"""

import markdown
import langid
from bs4 import BeautifulSoup
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Readme stopwords generated by chatgpt
custom_stopwords = [
    'motivation', 'library', 'online', 'https', 'add', 'table', 'method', 
    'background', 'section', 'BSD', 'version', 'type', 'demo', 'comment', 
    'function', 'footer', 'update', 'notation', 'parameter', 'plugin', 
    'run', 'branch', 'quickstart', 'badge', 'GitHub', 'warning', 'contribute', 
    'report', 'thank', 'symbol', 'instruction', 'issue', 'open', 'getting', 
    'scenario', 'example', 'require', 'using', 'acknowledge', 'operator', 
    'setup', 'about', 'settings', 'objective', 'user', 'paragraph', 'contributor', 
    'attribute', 'module', 'sample', 'unordered', 'description', 'question', 
    'introduction', 'repository', 'test', 'cite', 'maintainer', 'pull', 'note', 
    'howto', 'documentation', 'abbreviation', 'toc', 'blog', 'citation', 'answer', 
    'installation', 'list', 'website', 'change', 'status', 'proprietary', 'api', 
    'limitation', 'subsection', 'interface', 'Apache', 'step-by-step', 'commented', 
    'bug', 'icon', 'http', 'faq', 'purpose', 'term', 'idea', 'web', 'features', 
    'uncommented', 'publication', 'item', 'enum', 'visit', 'snippet', 'scope', 
    'input', 'usage', 'configuration', 'docs', 'bullet', 'navigation', 'argument', 
    'post', 'build', 'dependencies', 'acronym', 'gratis', 'resource', 'banner', 
    'requirements', 'to-do', 'architecture', 'xxx', 'fix', 'tool', 'path', 'goal', 
    'pattern', 'index', 'read', 'create', 'why', 'README', 'data', 'GPL', 'information', 
    'reserved', 'script', 'tutorial', 'enumeration', 'page', 'hint', 'issues', 'closed', 
    'placeholder', 'started', 'pip', 'todo', 'class', 'namespace', 'output', 'uncomment', 
    'framework', 'contributing', 'style', 'paper', 'case', 'copy', 'option', 'abstract', 
    'instance', 'disclaimer', 'request', 'structure', 'constant', 'definition', 'layout', 
    'acknowledgment', 'code', 'setting', 'image', 'GNU', 'fixme', 'guide', 'project', 
    'developer', 'owner', 'highlight', 'logo', 'important', 'virtualenv', 'right',
    'content', 'design', 'freeware', 'free', 'reference', 'template', 'environment', 
    'aim', 'ordered', 'overview', 'tip', 'config', 'admin', 'concept', 'directory', 
    'readme', 'download', 'link', 'organization', 'license', 'contribution', 'theme', 
    'info', 'extension', 'trick', 'object', 'attention', 'prerequisite', 'server', 
    'edit', 'file', 'install', 'enhancement', 'get', 'rights', 'hack', 'conda', 
    'feature', 'integration', 'master', 'command', 'caution', 'article', 'copyright', 
    'outline', 'MIT', 'number', 'property', 'header', 'point', 'site', 'delete', 
    'commercial', 'thanks', 'dependency', 'client', 'support', 'execute', 'author', 
    'remove', 'modify', 'notebook', 'variable', 'target', 'implementation', 'develop', 
    'source', 'summary', 'intro', 'step', 'merge', 'package', 'coverage', 'inspiration',
    'folder', 'contributors', 'click', 'configure', 'use', 'mode', 'based', 'ccd', 'random',
    'contains', 'used', 'written', 'el', 'state', 'en', 'hhl', 'different', 'like', 'examples', 
    'something', 'anything', 'import'
    ]

def preprocess_docs(docs):
    """
    Preprocess a list of documents using the preprocess_document function.

    Parameters
    ----------
    docs : list
        A list of strings representing documents.

    Returns
    -------
    list
        A list of preprocessed documents.
    """
    preprocessed_documents = [preprocess_document(document)
                              for document in docs]

    return preprocessed_documents


def preprocess_document(document):
    """
    Preprocess a single document by removing Markdown layout, tokenizing text,
    removing punctuation and non-alphabetic characters, and lemmatizing words.

    Parameters
    ----------
    document : str
        The input document as a string.

    Returns
    -------
    str
        The preprocessed document.
    """
    # Detect language
    lang, _ = langid.classify(document)

    # Check if the detected language is English
    if lang != 'en':
        return ''  # Return an empty string for non-English documents

    # Remove markdown layout
    html_document = markdown.markdown(document)
    processed_document = ''.join(BeautifulSoup(
        html_document,
        features="html.parser").findAll(string=True))

    # Tokenize text
    tokens = word_tokenize(processed_document)

    # Remove punctuation and non-alphabetic characters
    tokens = [word for word in tokens if word.isalpha()]

    # Lemmatize words
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]

    # Combine NLTK stopwords, custom stopwords, and additional stopwords
    stop_words = set(stopwords.words("english"))
    if custom_stopwords:
        stop_words.update(custom_stopwords)
    tokens = [word for word in tokens if word.lower() not in stop_words]

    preprocessed_document = " ".join(tokens)

    return preprocessed_document
